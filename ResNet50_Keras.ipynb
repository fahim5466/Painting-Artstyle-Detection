{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahim5466/Painting-Artstyle-Detection/blob/main/ResNet50_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CTlk9bRSpIC"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUVG3CoyUHEo"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "from scipy.misc import imresize\n",
        "import pickle, cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "'''\n",
        "Read in images and accompanying metadata to create sampled dataset consisting of 200 images from the ten art styles of interest. Save processed datasets to file.\n",
        "'''\n",
        "\n",
        "def make_img_df():\n",
        "    img_root = '/content/drive/My Drive/Artsy/Expressionism/'\n",
        "    img_details = pd.read_csv('/content/drive/My Drive/Artsy/all_data_info.csv')\n",
        "    keepers = ['Impressionism',\n",
        "                'Expressionism',\n",
        "               'Surrealism'\n",
        "                ]\n",
        "\n",
        "    df_details = img_details[img_details['style'].isin(keepers)]\n",
        "    img_names = df_details['new_filename'].values\n",
        "\n",
        "    files = [f for f in os.listdir(img_root) if os.path.isfile(os.path.join(img_root, f))]\n",
        "\n",
        "    art_list = []\n",
        "    for name in files:\n",
        "        if name in img_names:\n",
        "            img_path = '{}{}'.format(img_root, name)\n",
        "            art_list.append(img_path)\n",
        "\n",
        "    names = []\n",
        "    for path in art_list:\n",
        "        img = cv2.imread(path, 1)\n",
        "        try:\n",
        "            img.shape\n",
        "            names.append(path.lstrip(img_root))\n",
        "        except AttributeError:\n",
        "            continue\n",
        "\n",
        "    styles = [df_details.loc[df_details['new_filename'] == name, 'style'].iloc[0] for name in names]\n",
        "\n",
        "    images = ['{}{}'.format(img_root, name) for name in names]\n",
        "\n",
        "    final_df = pd.DataFrame({'img_path':images, 'class':styles})\n",
        "    final_df.to_pickle('/content/drive/My Drive/Artsy/paths_classes_10.pkl')\n",
        "\n",
        "\n",
        "def prepare_data():\n",
        "    df = pd.read_pickle('/content/drive/My Drive/Artsy/paths_classes_10.pkl')\n",
        "\n",
        "    paths_and_classes_small, class_names = sampled_paths_classes(df)\n",
        "\n",
        "    with open('/content/drive/My Drive/Artsy/paths_and_classes_small.pkl', 'wb') as f:\n",
        "        pickle.dump(paths_and_classes_small, f)\n",
        "\n",
        "    class_dict = {index: art_class for index, art_class in zip(range(10), class_names)}\n",
        "\n",
        "    with open('/content/drive/My Drive/Artsy/class_dict.pkl', 'wb') as f:\n",
        "        pickle.dump(class_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    images = [cv2.imread(path,1) for path, label in paths_and_classes_small]\n",
        "\n",
        "    x = np.array([prepare_image(image) for image in images])\n",
        "    y = np.array([style for path, style in paths_and_classes_small])\n",
        "\n",
        "    np.savez('/content/drive/My Drive/Artsy/images_labels_224.npz', x=x, y=y)\n",
        "\n",
        "\n",
        "def sampled_paths_classes(df):\n",
        "    # encode art categories as numerical values\n",
        "    encoder = LabelEncoder()\n",
        "    y = encoder.fit_transform(df['class'].astype('str'))\n",
        "    n_classes = len(np.unique(y))\n",
        "    paths_and_classes = list(zip(df['img_path'].tolist(), y))\n",
        "\n",
        "    paths_and_classes_small = []\n",
        "    for x in range(n_classes):\n",
        "        temp = [(path, style) for path, style in paths_and_classes if style == x]\n",
        "        samp = sample(temp, 200)\n",
        "        for path, style in samp:\n",
        "            paths_and_classes_small.append((path,style))\n",
        "\n",
        "    np.random.shuffle(paths_and_classes_small)\n",
        "\n",
        "    return paths_and_classes_small, encoder.classes_\n",
        "\n",
        "\n",
        "def prepare_image(image, target_width=224, target_height=224, max_zoom=0.2):\n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "    image_ratio = width / height\n",
        "    target_image_ratio = target_width / target_height\n",
        "    crop_vertically = image_ratio < target_image_ratio\n",
        "    crop_width = width if crop_vertically else int(height * target_image_ratio)\n",
        "    crop_height = int(width / target_image_ratio) if crop_vertically else height\n",
        "\n",
        "    resize_factor = np.random.rand() * max_zoom + 1.0\n",
        "    crop_width = int(crop_width / resize_factor)\n",
        "    crop_height = int(crop_height / resize_factor)\n",
        "\n",
        "    x0 = np.random.randint(0, width - crop_width)\n",
        "    y0 = np.random.randint(0, height - crop_height)\n",
        "    x1 = x0 + crop_width\n",
        "    y1 = y0 + crop_height\n",
        "\n",
        "    image = image[y0:y1, x0:x1]\n",
        "\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = np.fliplr(image)\n",
        "\n",
        "    image = imresize(image, (target_width, target_height))\n",
        "\n",
        "    return image.astype(np.float32) / 255\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    make_img_df()\n",
        "prepare_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zxrFHzWiNVN"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "import pickle, cv2\n",
        "from scipy.misc import imresize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import applications, optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "'''\n",
        "Train and save a Keras CNN model using the ResNet50 baseline model\n",
        "'''\n",
        "\n",
        "def train_validation_split(x, y):\n",
        "    # split data into training and test sets\n",
        "    X_training, X_test, y_training, y_test = train_test_split(x, y, stratify=y, random_state=1337)\n",
        "\n",
        "    # split training into train and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, stratify=y_training, random_state=42)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "\n",
        "def one_hot(y_train, y_val, y_test, n_classes):\n",
        "    y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "    y_val = np_utils.to_categorical(y_val, n_classes)\n",
        "    y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "    return y_train, y_val, y_test\n",
        "\n",
        "\n",
        "def build_fit_save_cnn(input_shape, n_classes, epochs, batch_size, X_train, X_val, y_train, y_val):\n",
        "    base_model = applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    add_model = Sequential()\n",
        "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    add_model.add(Dense(512, activation='relu'))\n",
        "    add_model.add(Dropout(0.25))\n",
        "    add_model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "    # combine base model and fully connected layers\n",
        "    final_model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "\n",
        "    # specify SDG optimizer parameters\n",
        "    sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "    # compile model\n",
        "    final_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "    final_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_val, y_val))\n",
        "\n",
        "    score = final_model.evaluate(X_val, y_val, verbose=0)\n",
        "    print('Val. score:', score[0])\n",
        "    print('Val. accuracy:', score[1])\n",
        "\n",
        "    save_model(final_model)\n",
        "\n",
        "    return final_model\n",
        "\n",
        "\n",
        "def test_predict_score(model, X_test, y_test):\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    test_pred = model.predict(X_test)\n",
        "\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "    return test_pred, score\n",
        "\n",
        "\n",
        "def save_model(model):\n",
        "    model_json = model.to_json()\n",
        "    with open('/content/drive/My Drive/Artsy/saved_model/resnet_model.json', 'w') as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    model.save_weights('/content/drive/My Drive/Artsy/saved_model/resnet_model_weights.h5')\n",
        "    print('Model saved to disk!')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    seed = 1337\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    epochs = 30\n",
        "    batch_size = 25\n",
        "    input_shape = (224,224,3)\n",
        "\n",
        "    data = np.load('/content/drive/My Drive/Artsy/images_labels_224.npz')\n",
        "    x = data['x']\n",
        "    y = data['y']\n",
        "    n_classes = len(np.unique(y))\n",
        "\n",
        "    # train/validation split\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = train_validation_split(x, y)\n",
        "\n",
        "    # convert y to one-hot encoding\n",
        "    y_train, y_val, y_test = one_hot(y_train, y_val, y_test, n_classes)\n",
        "\n",
        "    # build, train, and save CNN model\n",
        "    final_model = build_fit_save_cnn(input_shape, n_classes, epochs, batch_size, X_train, X_val, y_train, y_val)\n",
        "\n",
        "    # score model on test set\n",
        "test_pred, score = test_predict_score(loaded_model, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}